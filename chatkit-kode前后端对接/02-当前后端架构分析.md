# 当前后端架构分析（OpenAI ChatKit Server）

## 概述
当前后端使用 FastAPI + OpenAI ChatKit Server SDK + OpenAI Agents SDK 实现。

## 技术栈

- **Web 框架**: FastAPI
- **对话框架**: OpenAI ChatKit Server SDK
- **Agent 框架**: OpenAI Agents SDK
- **存储**: 内存存储（MemoryStore）
- **LLM**: 配置为 ZhipuAI/GLM-4.6（通过 ModelScope API）

## 目录结构

```
backend/app/
├── main.py           # FastAPI 应用入口
├── chat.py           # ChatKit Server 实现
├── constants.py      # 系统提示词和模型配置
├── facts.py          # Facts 数据模型和存储
├── memory_store.py   # 会话记忆存储
├── weather.py        # 天气查询工具
└── sample_widget.py  # 天气小部件渲染
```

## 核心组件分析

### 1. main.py - FastAPI 路由

**提供的 API 端点：**

```python
# 核心对话接口（SSE 流式）
POST /chatkit
  - 接收 ChatKit 协议请求
  - 调用 FactAssistantServer.process()
  - 返回 SSE 流式响应

# Facts 管理接口（可选）
GET /facts                    # 列出所有 facts
POST /facts/{fact_id}/save    # 标记 fact 为已保存
POST /facts/{fact_id}/discard # 丢弃 fact

# 健康检查
GET /health
```

### 2. chat.py - ChatKit Server 核心

**FactAssistantServer 类：**

```python
class FactAssistantServer(ChatKitServer[dict[str, Any]]):
    def __init__(self):
        self.store: MemoryStore = MemoryStore()  # 会话存储
        self.assistant = Agent[FactAgentContext](
            model=MODEL,                           # ZhipuAI/GLM-4.6
            name="ChatKit Guide",
            instructions=INSTRUCTIONS,             # 系统提示词
            tools=[save_fact, switch_theme, get_weather]
        )
    
    async def respond(
        self, 
        thread: ThreadMetadata,
        item: UserMessageItem | None,
        context: dict[str, Any]
    ) -> AsyncIterator[ThreadStreamEvent]:
        # 1. 准备 Agent 上下文
        # 2. 转换用户输入为 Agent 输入格式
        # 3. 运行 Agent 流式推理
        # 4. 流式返回事件
```

**关键处理流程：**

```
用户消息
  ↓
respond() 方法
  ↓
转换为 Agent 输入格式
  ↓
Runner.run_streamed(assistant, input, context)
  ↓
stream_agent_response(context, result)
  ↓
生成 ThreadStreamEvent
  ↓
返回 SSE 流
```

### 3. Agent 工具定义

**save_fact - 保存用户分享的事实**

```python
@function_tool(description_override="Record a fact shared by the user...")
async def save_fact(
    ctx: RunContextWrapper[FactAgentContext],
    fact: str,
) -> dict[str, str] | None:
    # 1. 保存到 fact_store
    # 2. 发送隐藏上下文消息
    # 3. 触发客户端工具调用
    ctx.context.client_tool_call = ClientToolCall(
        name="record_fact",
        arguments={"fact_id": confirmed.id, "fact_text": confirmed.text}
    )
    return {"fact_id": confirmed.id, "status": "saved"}
```

**switch_theme - 切换主题**

```python
@function_tool(description_override="Switch the chat interface...")
async def switch_theme(
    ctx: RunContextWrapper[FactAgentContext],
    theme: str,
) -> dict[str, str] | None:
    # 触发客户端工具调用
    ctx.context.client_tool_call = ClientToolCall(
        name="switch_theme",
        arguments={"theme": requested}
    )
    return {"theme": requested}
```

**get_weather - 天气查询**

```python
@function_tool(description_override="Look up the current weather...")
async def get_weather(
    ctx: RunContextWrapper[FactAgentContext],
    location: str,
    unit: Literal["celsius", "fahrenheit"] | str | None = None,
) -> dict[str, str | None]:
    # 1. 查询天气数据
    # 2. 渲染天气小部件
    # 3. 流式发送小部件
    await ctx.context.stream_widget(widget, copy_text=copy_text)
    return {...}
```

### 4. 系统提示词（constants.py）

```python
INSTRUCTIONS = """
You are ChatKit Guide, an onboarding assistant that primarily helps users 
understand how to use ChatKit and to record short factual statements 
about themselves.

Begin every new thread by encouraging the user to tell you about 
themselves, starting with the question 'Tell me about yourself.' 

Each time the user shares a concrete fact, call the `save_fact` tool 
with a short, declarative summary so it is recorded immediately.

When a user asks to switch themes, call the `switch_theme` tool...

When a user asks about the weather, call the `get_weather` tool...
"""

MODEL = "ZhipuAI/GLM-4.6"
```

### 5. 数据模型

**Fact 数据结构：**

```python
class Fact:
    id: str              # 唯一 ID
    text: str            # 事实内容
    status: str          # saved/pending/discarded
    createdAt: str       # ISO 时间戳
```

**FactAgentContext 上下文：**

```python
class FactAgentContext(AgentContext):
    store: MemoryStore           # 会话存储
    request_context: dict        # 请求上下文
    thread: ThreadMetadata       # 当前会话线程
    client_tool_call: ClientToolCall | None  # 客户端工具调用
```

## ChatKit 协议要点

### SSE 事件格式

```
event: thread.stream
data: {"type": "text.delta", "delta": "Hello"}

event: thread.stream  
data: {"type": "client_tool_call", "name": "switch_theme", "arguments": {...}}

event: thread.stream
data: {"type": "thread_item.done", "item": {...}}
```

### 客户端工具调用机制

1. Agent 调用工具时设置 `ctx.context.client_tool_call`
2. ChatKit Server 自动生成 `client_tool_call` 事件
3. 前端接收并执行客户端工具
4. 前端返回执行结果
5. 后端继续处理流程

### 线程（Thread）管理

- 每个会话有唯一的 `thread_id`
- 存储在 `MemoryStore` 中
- 支持多轮对话上下文

## 当前后端的优缺点

### ✅ 优点

1. **ChatKit 协议兼容**: 前端无需修改即可工作
2. **流式响应**: 良好的用户体验
3. **客户端工具**: 灵活的前后端交互
4. **工具系统**: 清晰的工具定义和调用机制

### ❌ 局限性

1. **依赖 OpenAI SDK**: 需要 OpenAI Agents SDK
2. **存储简单**: 仅内存存储，无持久化
3. **扩展性**: 与 ChatKit 协议强耦合
4. **文件操作**: 不支持文件系统、代码编辑等高级功能

## API 配置

**环境变量设置（代码中硬编码）：**

```python
os.environ["OPENAI_API_KEY"] = "ms-79845e97-7431-48d6-a2a9-085b92401866"
os.environ["OPENAI_BASE_URL"] = "https://api-inference.modelscope.cn/v1"
```

**模型配置：**

```python
model=MODEL,  # "ZhipuAI/GLM-4.6"
model_settings=ModelSettings(temperature=0.7)
```

## 部署方式

**启动命令：**
```bash
cd backend
uvicorn app.main:app --reload --port 8001
```

**访问地址：**
- API: http://localhost:8001
- ChatKit 端点: http://localhost:8001/chatkit
- Facts API: http://localhost:8001/facts

